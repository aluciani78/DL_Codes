{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWQC8iCE2_-o"
   },
   "source": [
    "# **Milestone 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DYdEI31whyE-"
   },
   "source": [
    "We have built two Convolutional Neural Network architectures in Milestone 1. Here, we will further try to achieve better performance by increasing the number of parameters/weights. Therefore, we will start this Milestone with three popular Transfer Learning architectures, namely, VGG16, ResNet v2, and Efficient Net. Please feel free to explore other pre-trained models as well. Link to Keras documentation for pre-trained models - https://keras.io/api/applications/\n",
    "\n",
    "**Note:** We will mount our drive and import our dataset once again for Milestone 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HDM89XHyCxrA"
   },
   "source": [
    "## **Mounting the Drive**\n",
    "\n",
    "**NOTE:**  Please use Google Colab from your browser for this notebook. **Google.colab is not a library that can be downloaded locally on your device.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JQi_degJC3dm",
    "outputId": "70feb0a1-5cab-4be2-e92f-b1dbc89a3e3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Mounting the drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UC8-yLUUCcWh"
   },
   "source": [
    "## **Importing the Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30fd2144"
   },
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# Importing Deep Learning Libraries\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, GlobalAveragePooling2D, Flatten, Conv2D, BatchNormalization, Activation, MaxPooling2D, LeakyReLU\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nCqJk2XpCnJi"
   },
   "source": [
    "### **Let us load the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_syvBdMlDTsr"
   },
   "source": [
    "**Note:** \n",
    "- You must download the dataset from the link provided on Olympus and upload the same on your Google drive before executing the code in the next cell.\n",
    "- In case of any error, please make sure that the path of the file is correct as the path may be different for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sMfr4tK04C0o"
   },
   "outputs": [],
   "source": [
    "# Storing the path of the data file from the Google drive\n",
    "path = '/content/drive/MyDrive/Facial_emotion_images.zip'\n",
    "\n",
    "# The data is provided as a zip file so we need to extract the files from the zip file\n",
    "with zipfile.ZipFile(path, 'r') as zip_ref:\n",
    "    zip_ref.extractall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4e89d1c7"
   },
   "outputs": [],
   "source": [
    "picture_size = 48\n",
    "folder_path = \"Facial_emotion_images/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "boQi7epI3Lsu"
   },
   "source": [
    "## **Transfer Learning Architectures**\n",
    "\n",
    "In this section, we will create several Transfer Learning architectures. For the pre-trained models, we will select three popular architectures namely, VGG16, ResNet v2, and Efficient Net. The difference between these architectures and the previous architectures is that these will require 3 input channels while the earlier ones worked on 'grayscale' images. Therefore, we need to create new DataLoaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7NKTPgdEsgt"
   },
   "source": [
    "### **Creating our Data Loaders for Transfer Learning Architectures**\n",
    "\n",
    "In this section, we are creating data loaders that we will use as inputs to our Neural Network. Unlike in Milestone 1, we will have to go with color_mode = 'rgb' as this is the required format for the transfer learning architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d97fee2d"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range = (0., 2.),\n",
    "                                    rescale = 1./255,\n",
    "                                    shear_range = 0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = 'rgb',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vaUYQdkf7pDG"
   },
   "source": [
    "## **VGG16 Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ThCSNrWC4HW0"
   },
   "source": [
    "### **Importing the VGG16 Architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7c83c83e"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "vgg = VGG16(include_top = False, weights = 'imagenet', input_shape = (48, 48, 3))\n",
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X76HMyZX4edM"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this model, we will import till the **'block5_pool'** layer of the VGG16 model. You can scroll down in the model summary and look for 'block5_pool'. You can choose any other layer as well.\n",
    "* Then we will add a Flatten layer, which receives the output of the 'block5_pool' layer as its input.\n",
    "* We will add a few Dense layers and use 'relu' activation function on them.\n",
    "* You may use Dropout and BatchNormalization layers as well.\n",
    "* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8b123bc6"
   },
   "outputs": [],
   "source": [
    "transfer_layer = vgg.get_layer('block5_pool')\n",
    "vgg.trainable = False\n",
    "\n",
    "# Add classification layers on top of it  \n",
    "____________\n",
    "\n",
    "# Flattenning the output from the 3rd block of the VGG16 model\n",
    "x = Flatten()(transfer_layer.output)\n",
    "\n",
    "# Adding a Dense layer with 256 neurons\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "# Add a Dense Layer with 128 neurons\n",
    "____________\n",
    "\n",
    "# Add a DropOut layer with Drop out ratio of 0.3\n",
    "____________\n",
    "\n",
    "# Add a Dense Layer with 64 neurons\n",
    "____________\n",
    "\n",
    "# Add a Batch Normalization layer\n",
    "____________\n",
    "\n",
    "# Adding the final dense layer with 4 neurons and use 'softmax' activation\n",
    "pred = Dense(4, activation='softmax')(x)\n",
    "\n",
    "vggmodel = Model(vgg.input, pred) # Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6vK7u7w8GsM"
   },
   "source": [
    "### **Compiling and Training the VGG16 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "86b249f1"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./vggmodel.h5\", monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor = 'val_loss',\n",
    "                          min_delta = 0,\n",
    "                          patience = 3,\n",
    "                          verbose = 1,\n",
    "                          restore_best_weights = True\n",
    "                          )\n",
    "\n",
    "reduce_learningrate = ReduceLROnPlateau(monitor = 'val_loss',\n",
    "                              factor = 0.2,\n",
    "                              patience = 3,\n",
    "                              verbose = 1,\n",
    "                              min_delta = 0.0001)\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0PN6ghMOGGgf"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile the vggmodel. Use categorical crossentropy as the loss function, Adam Optimizer with 0.001 learning rate, and set metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "893285ee"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train the model for 20 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Un-19jPckK07"
   },
   "source": [
    "### **Evaluating the VGG16 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6Y_bSLCkcvr"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tW6kPSky59Gv"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "- What do you infer from the general trend in the training performance? \n",
    "- Is the training accuracy consistently improving? \n",
    "- Is the validation accuracy also improving similarly?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YuTi6OAx8q_r"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AfC2Kx0v7Sa1"
   },
   "source": [
    "**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E0Mew4Cc7u7k"
   },
   "source": [
    "## **ResNet V2 Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "568a5c9a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as ap\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "Resnet = ap.ResNet101(include_top = False, weights = \"imagenet\", input_shape=(48,48,3))\n",
    "Resnet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay4RedCQlL4O"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this model, we will import till the **'conv5_block3_add'** layer of the ResNet model. You can scroll down in the model summary and look for 'conv5_block3_add'. You can choose any other layer as well.\n",
    "* Then we will add a Flatten layer, which receives the output of the 'conv5_block3_add' layer as its input.\n",
    "* We will add a few Dense layers and use 'relu' activation function on them.\n",
    "* You may use Dropout and BatchNormalization layers as well.\n",
    "* Then we will add our last dense layer, which must have 4 neurons and a 'softmax' activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "911d3335"
   },
   "outputs": [],
   "source": [
    "transfer_layer_Resnet = Resnet.get_layer('conv5_block3_add')\n",
    "Resnet.trainable=False\n",
    "\n",
    "# Add classification layers on top of it\n",
    "____________\n",
    "\n",
    "# Flattenning the output from the 3rd block of the VGG16 model\n",
    "x = Flatten()(transfer_layer_Resnet.output)\n",
    "\n",
    "# Add a Dense layer with 256 neurons\n",
    "x = Dense(256, activation = 'relu')(x)\n",
    "\n",
    "# Add a Dense Layer with 128 neurons\n",
    "____________\n",
    "\n",
    "# Add a DropOut layer with Drop out ratio of 0.3\n",
    "____________\n",
    "\n",
    "# Add a Dense Layer with 64 neurons\n",
    "____________\n",
    "\n",
    "# Add a Batch Normalization layer\n",
    "____________\n",
    "\n",
    "# Add the final dense layer with 4 neurons and use a 'softmax' activation\n",
    "pred = Dense(4, activation = 'softmax')(x)\n",
    "\n",
    "resnetmodel = Model(vgg.input, pred) # Initializing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Tmtcd1ZElpJy"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fe959789"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./Resnetmodel.h5\", monitor = 'val_acc', verbose = 1, save_best_only = True, mode = 'max')\n",
    "\n",
    "early_stopping = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "\n",
    "reduce_learningrate = _________ # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "\n",
    "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "641VUEtvGaLW"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your resnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mBZRmTFLIRtS"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McHEzBlhxw39"
   },
   "source": [
    "### **Evaluating the ResNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEl6IQf0xwci"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3htKZRdomiOY"
   },
   "source": [
    "**Observations and Insights:__**\n",
    "\n",
    "**Note: You can even go back and build your own architecture on top of the ResNet Transfer layer and see if you can improve the performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmnDG4ZbncoR"
   },
   "source": [
    "## **EfficientNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "613c7a71"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras.applications as ap\n",
    "from tensorflow.keras import Model\n",
    "EfficientNet = ap.EfficientNetV2B2(include_top=False,weights=\"imagenet\", input_shape= (48, 48, 3))\n",
    "\n",
    "EfficientNet.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kDNE8pVngqC"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "**Build your own Architecture on top of the transfer layer. Be sure to have a Flatten layer after your transfer layer and also make sure you have 4 neurons and softmax activation function in your last dense layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2b27a6e1"
   },
   "outputs": [],
   "source": [
    "transfer_layer_EfficientNet = EfficientNet.get_layer('block6e_expand_activation')\n",
    "EfficientNet.trainable = False\n",
    "\n",
    "# Add your Flatten layer.\n",
    "__________\n",
    "\n",
    "# Add your Dense layers and/or BatchNormalization and Dropout layers\n",
    "__________\n",
    "\n",
    "# Add your final Dense layer with 4 neurons and softmax activation function.\n",
    "__________\n",
    "\n",
    "Efficientnetmodel = Model(EfficientNet.input, pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hVv4Df_In32Y"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dc326cd3"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"./Efficientnetmodel.h5\", monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early_stopping = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "reduce_learningrate = _________  # Write your code here. You may play around with the hyperparameters if you wish.\n",
    "\n",
    "callbacks_list = [early_stopping,checkpoint,reduce_learningrate]\n",
    "\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U13gspW8I-e3"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your Efficientnetmodel. Use categorical crossentropy as your loss function, Adam Optimizer with 0.001 learning rate, and set your metrics to 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Doy0fkOwIew_"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as your training data and validation_set as your validation data. Train your model for 20 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2xjrzYpgoQnN"
   },
   "source": [
    "### **Evaluating the EfficientnetNet Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WJVFenvnoQnN"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWlk14FOoQnN"
   },
   "source": [
    "**Observations and Insights:__**\n",
    "\n",
    "**Note: You can even go back and build your own architecture on top of the VGG16 Transfer layer and see if you can improve the performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fk6QAcv5odNF"
   },
   "source": [
    "**Think About It:**\n",
    "\n",
    "* What is your overall performance of these Transfer Learning Architectures? Can we draw a comparison of these models' performances. Are we satisfied with the accuracies that we have received?\n",
    "* Do you think our issue lies with 'rgb' color_mode?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EH3atQP8q_v"
   },
   "source": [
    "Now that we have tried multiple pre-trained models, let's build a complex CNN architecture and see if we can get better performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjKlBaZDpWoV"
   },
   "source": [
    "## **Building a Complex Neural Network Architecture**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bMFUj3Fpe75"
   },
   "source": [
    "In this section, we will build a more complex Convolutional Neural Network Model that has close to as many parameters as we had in our Transfer Learning Models. However, we will have only 1 input channel for our input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ejGfyYSbtx-F"
   },
   "source": [
    "## **Creating our Data Loaders**\n",
    "\n",
    "In this section, we are creating data loaders which we will use as inputs to the more Complicated Convolutional Neural Network. We will go ahead with color_mode = 'grayscale'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj1hM5_ttx-F"
   },
   "outputs": [],
   "source": [
    "batch_size  = 32\n",
    "img_size = 48\n",
    "\n",
    "datagen_train = ImageDataGenerator(horizontal_flip = True,\n",
    "                                    brightness_range = (0., 2.),\n",
    "                                    rescale = 1./255,\n",
    "                                    shear_range = 0.3)\n",
    "\n",
    "train_set = datagen_train.flow_from_directory(folder_path + \"train\",\n",
    "                                              target_size = (img_size, img_size),\n",
    "                                              color_mode = 'grayscale',\n",
    "                                              batch_size = batch_size,\n",
    "                                              class_mode = 'categorical',\n",
    "                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                              shuffle = True)\n",
    "\n",
    "\n",
    "datagen_validation = # Write your code here\n",
    "\n",
    "validation_set = # Write your code here\n",
    "\n",
    "datagen_test = # Write your code here\n",
    "\n",
    "test_set = # Write your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ft5U6f1Wie2R"
   },
   "source": [
    "### **Model Building**\n",
    "\n",
    "* In this network, we plan to have 5 Convolutional Blocks\n",
    "* Add first Conv2D layer with **64 filters** and a **kernel size of 2**. Use the 'same' padding and provide the **input shape = (48, 48, 1)**. Use **'relu' activation**.\n",
    "* Add your BatchNormalization layer followed by a LeakyRelU layer with Leaky ReLU parameter of **0.1**\n",
    "* Add MaxPooling2D layer with **pool size = 2**.\n",
    "* Add a Dropout layer with a Dropout Ratio of **0.2**. This completes the first Convolutional block.\n",
    "* Add a second Conv2D layer with **128 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.**\n",
    "* Follow this up with a similar BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer like above to complete your second Convolutional Block.\n",
    "* Add a third Conv2D layer with **512 filters** and a **kernel size of 2**. Use the **'same' padding** and **'relu' activation.** Once again, follow it up with a BatchNormalization, LeakyRelU, Maxpooling2D, and Dropout layer to complete your third Convolutional block.\n",
    "* Add a fourth block, with the Conv2D layer having **512 filters**.\n",
    "* Add the fifth block, having **128 filters**.\n",
    "* Then add your Flatten layer, followed by your Dense layers.\n",
    "* Add your first Dense layer with **256 neurons** followed by a BatchNormalization layer, a **'relu'** Activation, and a Dropout layer. This forms your first Fully Connected block\n",
    "* Add your second Dense layer with **512 neurons**, again followed by a BatchNormalization layer, **relu** activation, and a Dropout layer.\n",
    "* Add your final Dense layer with 4 neurons.\n",
    "* Compile your model with the optimizer of your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "37f9194d"
   },
   "outputs": [],
   "source": [
    "no_of_classes = 4\n",
    "\n",
    "model3 = Sequential()\n",
    "\n",
    "# Add 1st CNN Block\n",
    "____________\n",
    "\n",
    "# Add 2nd CNN Block\n",
    "____________\n",
    "\n",
    "# Add 3rd CNN Block\n",
    "____________\n",
    "\n",
    "# Add 4th CNN Block\n",
    "____________\n",
    "\n",
    "# Add 5th CNN Block\n",
    "____________\n",
    "\n",
    "model3.add(Flatten())\n",
    "\n",
    "# First fully connected layer\n",
    "____________\n",
    "\n",
    "# Second fully connected layer\n",
    "____________\n",
    "\n",
    "model3.add(Dense(no_of_classes, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fyc0B--hwTHS"
   },
   "source": [
    "### **Compiling and Training the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0edabf52"
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, CSVLogger\n",
    "\n",
    "epochs = 35\n",
    "\n",
    "steps_per_epoch = train_set.n//train_set.batch_size\n",
    "validation_steps = validation_set.n//validation_set.batch_size\n",
    "\n",
    "checkpoint = ModelCheckpoint(\"model3.h5\", monitor = 'val_accuracy',\n",
    "                            save_weights_only = True, model = 'max', verbose = 1)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, min_lr = 0.0001 , model = 'auto')\n",
    "\n",
    "callbacks = [checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IYDJwZWmKSK6"
   },
   "outputs": [],
   "source": [
    "# Write your code to compile your model3. Use categorical crossentropy as the loss function, Adam Optimizer with 0.003 learning rate, and set metrics to 'accuracy'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_tB9HX5sKjUL"
   },
   "outputs": [],
   "source": [
    "history = # Write your code to fit your model. Use train_set as the training data and validation_set as the validation data. Train your model for 35 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BbAqrAQQVjIR"
   },
   "source": [
    "### **Evaluating the Model on Test Set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uO26AYRuVm7F"
   },
   "outputs": [],
   "source": [
    "# Write your code to evaluate the model performance on the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81uYGSmHwxfD"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNWc6agwxJ_z"
   },
   "source": [
    "### **Plotting the Confusion Matrix for the chosen final model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SFTRyIk-yjoQ"
   },
   "outputs": [],
   "source": [
    "# Plot the confusion matrix and generate a classification report for the model\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "test_set = datagen_test.flow_from_directory(folder_path + \"test\",\n",
    "                                                              target_size = (img_size,img_size),\n",
    "                                                              color_mode = 'grayscale',\n",
    "                                                              batch_size = 128,\n",
    "                                                              class_mode = 'categorical',\n",
    "                                                              classes = ['happy', 'sad', 'neutral', 'surprise'],\n",
    "                                                              shuffle = True) \n",
    "test_images, test_labels = next(test_set)\n",
    "\n",
    "# Write the name of your chosen model in the blank\n",
    "pred = ________.predict(test_images)\n",
    "pred = np.argmax(pred, axis = 1) \n",
    "y_true = np.argmax(test_labels, axis = 1)\n",
    "\n",
    "# Printing the classification report\n",
    "_____________\n",
    "\n",
    "# Plotting the heatmap using confusion matrix\n",
    "cm = confusion_matrix(y_true, pred)\n",
    "plt.figure(figsize = (8, 5))\n",
    "sns.heatmap(cm, annot = True,  fmt = '.0f', xticklabels = ['happy', 'sad', 'neutral', 'surprise'], yticklabels = ['happy', 'sad', 'neutral', 'surprise'])\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LGgvpOrP8q_x"
   },
   "source": [
    "**Observations and Insights:__**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6s_baiF_KllW"
   },
   "source": [
    "## **Conclusion:____________**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MEZPA_mN0tUo"
   },
   "source": [
    "### **Insights**\n",
    "\n",
    "### **Refined insights**:\n",
    "- What are the most meaningful insights from the data relevant to the problem?\n",
    "\n",
    "### **Comparison of various techniques and their relative performance**:\n",
    "- How do different techniques perform? Which one is performing relatively better? Is there scope to improve the performance further?\n",
    "\n",
    "### **Proposal for the final solution design**:\n",
    "- What model do you propose to be adopted? Why is this the best solution to adopt?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
